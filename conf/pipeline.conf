pipeline {
  cpu.interval = 2
  memory.interval = 3
}

kafka {
    consumer {
      zookeeper.connect = "10.10.10.8:2181,10.10.10.96:2181,10.10.10.117:2181/kafka"
      # consumer topics separated by ","
      topics = "demogate"
      client.id = "pipeline-app"
      socket.timeout.ms = 30000
      socket.receive.buffer.bytes = 65536
      fetch.message.max.bytes = 1048576
      emit.batch.size = 100
      fetch.threshold = 5000
      fetch.sleep.ms = 100
    }
  
    producer {
      topic = "demogate"
      # list of host/port pairs to use for establishing the initial connection to kafka server
      # list should be in the form "host1:port1,host2:port2,..."
      # list need not contain the full set of servers
      bootstrap.servers = "10.10.10.8:9092,10.10.10.96:9092,10.10.10.117:9092"
      acks = "1"
      buffer.memory = 33554432
      compression.type = "none"
      retries = 0
      batch.size = 16384
    }
  
    storage.replicas = 2
  
    grouper.factory.class = "org.apache.gearpump.streaming.kafka.lib.grouper.KafkaDefaultGrouperFactory"
  
    task {
      message.decoder.class = "org.apache.gearpump.streaming.kafka.lib.KafkaDecoder"
      timestamp.filter.class = "org.apache.gearpump.streaming.kafka.lib.KafkaFilter"
    }
}

hbase {
  zookeeper.connect = "ip-10-10-10-117.eu-west-1.compute.internal,ip-10-10-10-8.eu-west-1.compute.internal,ip-10-10-10-96.eu-west-1.compute.internal"
}
