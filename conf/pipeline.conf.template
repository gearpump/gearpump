gearpump {
  serializers {
    "org.apache.gearpump.experiments.pipeline.Messages$Datum" = ""
    "[Lorg.apache.gearpump.experiments.pipeline.Messages$Datum;" = ""
  }
}

pipeline {
  cpu.interval = 10
  memory.interval = 20
  processors = 1
  persistors = 1
}

kafka {
    consumer {
      # consumer topics separated by ","
      topics = "demogate"
      emit.batch.size = 100
      fetch.threshold = 5000
      fetch.sleep.ms = 100
    }
  
    producer {
      topic = "demogate"
      # list of host/port pairs to use for establishing the initial connection to kafka server
      # list should be in the form "host1:port1,host2:port2,..."
      # list need not contain the full set of servers
      batch.size = 16384
    }
  
    storage.replicas = 2
  
    grouper.factory.class = "org.apache.gearpump.streaming.kafka.lib.grouper.KafkaDefaultGrouperFactory"
  
    task {
      message.decoder.class = "org.apache.gearpump.streaming.kafka.lib.DefaultMessageDecoder"
      timestamp.filter.class = "org.apache.gearpump.streaming.kafka.lib.KafkaFilter"
    }
}

hbase {
  zookeeper.connect = "127.0.0.1"
  table {
    name = "pipeline"
    column {
      family = "metrics"
      name = "average"
    }
  }
}
