#########################################
### This is the default configuration for gearpump
### To use the application, you at least need to change gearpump.cluster to point to right master
#########################################
gearpump {

  ###########################
  ### Change the dispather for tasks
  ### If you don't know what this is about, don't change it
  ###########################

  task-dispatcher {
    mailbox-type = "akka.dispatch.SingleConsumerOnlyUnboundedMailbox"
    throughput = 100
    fork-join-executor {
      parallelism-factor = 2
      parallelism-max = 8
      parallelism-min = 2
    }
  }

  ## The installation folder of gearpump
  home = ""

  ###########################
  ### Metrics setting,
  ### If you want to use metrics, please change
  ###########################


  ### Flag to enable metrics
  metrics {
    enabled = false

    # We will take one metric out of ${sample.rate}
    sample-rate = 1

    report-interval-ms = 15000

    # reporter = "graphite"
    # reporter = "akka"
    reporter = "akka"

    graphite {
      ## Graphite host settings
      host = "127.0.0.1"
      port = 2003
    }

    logfile {

    }

    ## Coarse-grain history metrics, which have a larger timespan but sparse data points
    retainHistoryData {
      # max hours of history data to retain
      # Note: due to implementation limitation(we store all history in memory),
      # please don't set this to too big which may exhaust memory.
      hours = 72

      # time interval between two data points for history data (unit: ms)
      # Usually this value is set to a big value so that we only store
      # coarse-grain data
      intervalMs = 3600000
    }

    ## fine-grain recent metrics which just happened, which have a smaller timespan but dense data points
    retainRecentData {

      # max seconds of recent data to retain,
      # THis is for the fine-grain data
      seconds = 300

      # time interval between two data points for recent data (unit: ms)
      intervalMs = 15000
    }
  }

  ## Whether to enable remote-debug mode.
  ## In remote debug mode, every executor process will bind to a free port, and
  ## listen for remote jvm debug.
  remote-debug-executor-jvm = false

  ### verbose gc
  ### turn on JVM verbose GC
  ### We will use -verbose:gc -Xloggc: -XX:+PrintGCDetails
  ### -XX:+PrintGCDateStamps -XX:+PrintTenuringDistribution
  ### -XX:+PrintGCApplicationConcurrentTime
  ### -XX:+PrintGCApplicationStoppedTime
  verbose-gc = false

  #######################################
  ### Logging settings
  #######################################
  # The log dir for daemon processes
  log.daemon.dir = "logs"

  # The log dir for applications
  log.application.dir = "logs"

  serializer.pool = "io.gearpump.serializer.FastKryoSerializerPool"

  serializers {
    ## Use default serializer for these types
    "scala.collection.immutable.List" = ""
    "scala.collection.immutable.Vector" = ""
    "scala.collection.immutable.$colon$colon" = ""
    "[B" = ""
    "[C" = ""
    "[S" = ""
    "[I" = ""
    "[J" = ""
    "[F" = ""
    "[D" = ""
    "[Z" = ""
    "[Ljava.lang.String;" = ""
    "scala.Array" = ""
    "scala.Tuple1" = ""
    "scala.Tuple2" = ""
    "scala.Tuple3" = ""
    "scala.Tuple4" = ""
    "scala.Tuple5" = ""
    "scala.Tuple6" = ""
    "akka.actor.LocalActorRef" = ""
  }

  ## How many slots each worker contains
  worker.slots = 100


  ##
  ## Executor share same process of worker
  worker.executor-share-same-jvm-as-worker = false

  ###################
  ### Appmaster JVM argument configuration
  ###################
  appmaster {
    vmargs = ""
    extraClasspath = ""
  }

  ###################
  ### Executor argument configuration
  ### Executor JVM can contains multiple tasks
  ###################
  executor {
    vmargs = ""
    extraClasspath = ""
  }

  ##############################
  ### Required to change!!
  ### You need to set the master cluster address here
  ###
  ###
  ### For example, you may start three master
  ### on node1: bin/master -ip node1 -port 3000
  ### on node2: bin/master -ip node2 -port 3000
  ### on node3: bin/master -ip node3 -port 3000
  ###
  ### Then you need to set the cluster.masters = ["node1:3000","node2:3000","node3:3000"]
  cluster {
    masters = []
  }

  ##############################
  ### Required to change!!
  ### You need to set the actual host name here
  ###
  hostname = "127.0.0.1"

  ### When the resource cannot be allocated in the timeout, then
  ### the appmaster will shutdown itself.
  resource-allocation-timeout-seconds = 10

  ### Define where the submitted jar file will be stored at

  ### This path follows the hadoop path schema
  ### For HDFS, use hdfs://host:port/path/
  ### For FTP, use ftp://host:port/path
  ### If you want to store on master nodes, then use local directory,
  ### jarstore.rootpath = "jarstore/" will points to relative directory where master is started.
  ### jarstore.rootpath = "/jarstore/" will points to absolute directory on master server
  jarstore.rootpath = "jarstore/"

  #########################
  ### Scheduller for master, it will use this scheduler to schedule resource for
  ### different applications.
  ### If you don't know what is this about, don't change it
  #########################
  scheduling {
    scheduler-class = "io.gearpump.cluster.scheduler.PriorityScheduler"
  }

  #############################################
  # Default Configuration for REST, WebSocket, Http services
  #############################################

  #########################
  ### services can be started by a command line tool bin/services
  ### If you don't know what is this about, don't change it
  #########################
  services {
    host = "127.0.0.1"
    http = 8090
    ws = 8091
  }

  #############################################
  ## Default Configuration for Gearpump Netty transport layer
  ## If you don't know what is this about, don't change it
  #############################################
  netty {
    buffer-size = 5242880
    max-retries = 30
    base-sleep-ms = 100
    max-sleep-ms = 1000
    message-batch-size = 262144
    flush-check-interval = 5 
  }
}

### Akka system configuration for master nodes
master {
  extensions = [
    "akka.contrib.datareplication.DataReplication$"
  ]
  akka {
    loglevel = "INFO"
    log-dead-letters = off
    log-dead-letters-during-shutdown = off
    actor {
      ## Master forms a akka cluster
      provider = "akka.cluster.ClusterActorRefProvider"
    }
    cluster {
      roles = ["master"]
      auto-down-unreachable-after = 15s
    }
    remote {
      log-remote-lifecycle-events = off
    }
  }
}

### Akka system configuration for worker nodes
worker {
  ## Add worker overrided config
  akka {
    loglevel = "INFO"
    log-dead-letters = off
    log-dead-letters-during-shutdown = off
    actor {
      provider = "akka.remote.RemoteActorRefProvider"
    }
    cluster {
      roles = ["worker"]
    }
    remote {
      log-remote-lifecycle-events = off
    }
  }

}


### application default configuration, it will override base
application {

}

### ui default configuration, it will override base
ui {

}

### Akka system configuration for master nodes, worker nodes, and clients
base {

  spray.can {
    ### allow user to post jar less than 200MB
    server.parsing.max-content-length = "1000M"
  }

  ## work-around to fix akka io performance issue on windows
  ## reference: http://stackoverflow.com/questions/29453848/high-cpu-on-akka-io-pinned-dispatcher-on-windows
  ## ticket: https://github.com/akka/akka/issues/16295
  akka.io.tcp.windows-connection-abort-workaround-enabled=off

  akka.scheduler.tick-duration = 1

  akka {

    http {
      client {
        parsing {
          max-content-length = 2048m
        }
      }
      server {
        parsing {
          max-content-length = 2048m
          illegal-header-warnings = off
        }
      }
    }

    test {
      ##  duration to wait in expectMsg in akka test
      single-expect-default = 10s
    }

    daemonic = on
  
    extensions = [
      "io.gearpump.transport.Express$",
      "io.gearpump.metrics.Metrics$"
    ]
    loglevel = "INFO"
    loggers = ["akka.event.slf4j.Slf4jLogger"]
    logging-filter = "akka.event.slf4j.Slf4jLoggingFilter"
    log-dead-letters = off
    log-dead-letters-during-shutdown = off
    actor {
      provider = "akka.remote.RemoteActorRefProvider"
      default-mailbox {
        mailbox-type = "akka.dispatch.SingleConsumerOnlyUnboundedMailbox"
      }
      default-dispatcher {
        mailbox-type = "akka.dispatch.SingleConsumerOnlyUnboundedMailbox"
        throughput = 10
        fork-join-executor {
          parallelism-factor = 2
          parallelism-max = 4
          parallelism-min = 4
        }
      }
      kryo {
        buffer-size = 4096
        classes = [
        ]

        compression = off
        idstrategy = "incremental"
        implicit-registration-logging = true
        kryo-reference-map = true
        kryo-trace = false
        mappings {
        }
        max-buffer-size = -1
        serializer-pool-size = 16
        type = "graph"
        use-manifests = false
      }
    }
    remote {
      log-remote-lifecycle-events = off
      use-dispatcher = "akka.remote.default-remote-dispatcher"
      enabled-transports = ["akka.remote.netty.tcp"]
      netty.tcp {
        hostname = "127.0.0.1"
        port = 0
        send-buffer-size = 4096000b
        receive-buffer-size = 4096000b
        maximum-frame-size = 2048000b
      }
      default-remote-dispatcher {
        throughput = 5
        type = Dispatcher
        mailbox-type = "akka.dispatch.SingleConsumerOnlyUnboundedMailbox"
        executor = "fork-join-executor"
      }
    }
  }
}

## Special configuration for windows system
windows {
  ### On windows, the value must be larger than 10ms, check
  ### https://github.com/akka/akka/blob/master/akka-actor/src/main/scala/akka/actor/Scheduler.scala#L204
  akka.scheduler.tick-duration = 10
}
